{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning HW01\n",
    "Gerald Baulig 0780827 2019/11/03\n",
    "\n",
    "In this assignment we are asked to implement a neural network from scratch,\n",
    "including Backpropagation and Storastic Gradient Decent algorithms.\n",
    "The assigment includes two tasks:\n",
    "\n",
    "1. Implement a regression network, and\n",
    "2. implement a classification network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a Regression Network\n",
    "\n",
    "Implement a regression network for the engery efficiency dataset.\n",
    "I guess this dataset descripes the termal exchange of a building to its environment.\n",
    "The dataset has 2 Values (t):\n",
    "\n",
    "- Heating load, and\n",
    "- Cooling load\n",
    "\n",
    "And 8 features:\n",
    "\n",
    "- Relative compactness,\n",
    "- Surface area,\n",
    "- Wall area,\n",
    "- Roof area,\n",
    "- Overall hight,\n",
    "- Orientation,\n",
    "- Glazing area, and\n",
    "- Glazing area distribution.\n",
    "\n",
    "We are required to define a feature-vector out of these features and predict the heating load of the buildings, by minimizing the \"sum-of-squares\" error function,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E(w) = \\sum_{n=1}^{N}{(t_n - y(X_n;w))^2}\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "...while the evaluation should be processed by the \"root-mean-square\" error (basically an Euclidean distance :-),\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E_{RMS}(w) = \\frac{\\sqrt{\\sum_{n=1}^{N}{(t_n - y(x_n;w))^2}}}{\\sqrt{N}}\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement a Classifier\n",
    "\n",
    "Implement a classification network for the Ionosphere dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Fully-Connected Neural Network from Scratch\n",
    "\n",
    "First, let's define what a Neural Network is.\n",
    "A Neural Network is a class that can train and validate the weight of a stack of layers, w.r.t several hyper-parameters.\n",
    "However, all what the Neural Network needs to know about his own network is, where to get its output from. Furthermore, the hyper-parameters are only required in the training process, but only few of them in the validation process,\n",
    "such that the class defination could look like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, train_set, val_set, cost_func, loss_func):\n",
    "        self.train_set = train_set\n",
    "        self.val_set = val_set\n",
    "        self.cost = cost_func\n",
    "        self.loss = loss_func\n",
    "        pass\n",
    "    \n",
    "    def train(self, output_layer, lr, lr_dec):\n",
    "        self.training = True\n",
    "        for Y in output_layer.poll_forward():\n",
    "            Z = np.squeeze(self.cost.f(self.Y, Y))\n",
    "            dZ = self.cost.d(self.Y, Y)\n",
    "            output_layer.push_backward(dZ, lr)\n",
    "            lr -= lr * lr_dec\n",
    "            yield Z \n",
    "        pass\n",
    "    \n",
    "    def val(self, output_layer):\n",
    "        self.training = False\n",
    "        for Y in output_layer.pool_forward():\n",
    "            Z = self.loss.f(self.Y, Y)\n",
    "            yield Z\n",
    "        pass\n",
    "    \n",
    "    def gen_input(self):\n",
    "        if self.training:\n",
    "            for self.X, self.Y, self.epoch, self.step in self.train_set:\n",
    "                yield self.X\n",
    "        else:\n",
    "            for self.X, self.Y, self.epoch, self.step in self.val_set:\n",
    "                yield self.X\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 5. 0. 0.]\n",
      "[1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class ReLU:\n",
    "    f = lambda x: np.maximum(x,0).astype(float)\n",
    "    d = lambda x: (x > 0).astype(float)\n",
    "\n",
    "#test\n",
    "print(ReLU.f(np.array([1,-1,5,-5,0])))\n",
    "print(ReLU.d(np.array([1,-1,5,-5,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.26894142 0.99330715 0.00669285 0.5       ]\n",
      "[0.19661193 0.19661193 0.00664806 0.00664806 0.25      ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Sigmoid:\n",
    "    f = lambda x: 1 / (1 + np.exp(-x))\n",
    "    def d(x):\n",
    "        S = Sigmoid.f(x)\n",
    "        return S * (1 - S)\n",
    "    pass\n",
    "\n",
    "#test\n",
    "print(Sigmoid.f(np.array([1,-1,5,-5,0])))\n",
    "print(Sigmoid.d(np.array([1,-1,5,-5,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Define a Fully-Connected Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcLayer:\n",
    "    def __init__(self,\n",
    "                 weights,\n",
    "                 bias,\n",
    "                 act_func,\n",
    "                 input_generator,\n",
    "                 backprop,\n",
    "                ):\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        self.act = act_func\n",
    "        self.input = input_generator\n",
    "        self.backprop = backprop\n",
    "        pass\n",
    "    \n",
    "    def poll_forward(self):\n",
    "        '''Polls the output from the underlying layer. (Feed Forward)'''\n",
    "        for self.x in self.input:\n",
    "            self.y = self.act.f(np.dot(self.x, self.w) + self.b)\n",
    "            yield self.y\n",
    "    \n",
    "    def push_backward(self, dZ, lr):\n",
    "        '''Pushes the loss to the underlying layer. (Back Propagation)'''\n",
    "        dZ = dZ * self.act.d(self.y)\n",
    "        dw = np.dot(self.x.T, dZ)\n",
    "        if self.backprop:\n",
    "            self.backprop(np.dot(dZ, self.w.T), lr)\n",
    "        self.w += dw * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS.f 17\n",
      "SOS.d [ 0 -2  0  8  0]\n",
      "RMS.f 1.8439088914585775\n",
      "RMS.d [ 0.  -0.2  0.   0.8  0. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class SOS:\n",
    "    f = lambda t,y: np.sum(np.power(t - y, 2))\n",
    "    d = lambda t,y: (t - y) * 2\n",
    "    \n",
    "class RMS:\n",
    "    f = lambda t,y: np.power(SOS.f(t, y) / t.size, 0.5)\n",
    "    d = lambda t,y: (SOS.d(t, y) / t.size) * 0.5\n",
    "\n",
    "#test\n",
    "print(\"SOS.f\", SOS.f(np.array([1,-2,5,-5,0]), np.array([1,-1,5,-9,0])))\n",
    "print(\"SOS.d\", SOS.d(np.array([1,-2,5,-5,0]), np.array([1,-1,5,-9,0])))\n",
    "print(\"RMS.f\", RMS.f(np.array([1,-2,5,-5,0]), np.array([1,-1,5,-9,0])))\n",
    "print(\"RMS.d\", RMS.d(np.array([1,-2,5,-5,0]), np.array([1,-1,5,-9,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for Energy Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Energy Efficiency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (768,5) into shape (768)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-bd3c00610163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mori\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0munpack_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-bd3c00610163>\u001b[0m in \u001b[0;36munpack_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mori\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0munpack_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (768,5) into shape (768)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unpack_data():\n",
    "    raw = np.genfromtxt('EnergyEfficiency_data.csv', skip_header=1, delimiter=',')\n",
    "    data = \n",
    "    N = raw.shape[0]\n",
    "    pre = data[:,:5]\n",
    "    ori = np.zeros((N,4))\n",
    "    ori[:,0] = data[:,5] == 2\n",
    "    ori[:,1] = data[:,5] == 3\n",
    "    ori[:,2] = data[:,5] == 4\n",
    "    ori[:,3] = data[:,5] == 5\n",
    "    glaz = data[:,6]\n",
    "    glaz_dist = np.zeros((N,5))\n",
    "    glaz_dist[:,0] = data[:,7] == 1\n",
    "    glaz_dist[:,1] = data[:,7] == 2\n",
    "    glaz_dist[:,2] = data[:,7] == 3\n",
    "    glaz_dist[:,3] = data[:,7] == 4\n",
    "    glaz_dist[:,4] = data[:,7] == 5\n",
    "    labels = data[:,8:]\n",
    "    \n",
    "    return np.array([pre, ori]), labels\n",
    "\n",
    "unpack_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.66017798]] [[0.]] 7.076546890472223\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[0.]] 0.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[1.]] 1.0\n",
      "[[0.]] [[0.]] 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,0]\n",
    "])\n",
    "\n",
    "def gen_data(data, epochs, batch_size):\n",
    "    step = 0\n",
    "    X = np.zeros((batch_size, data.shape[1]-1))\n",
    "    Y = np.zeros((batch_size, 1))\n",
    "    for e in range(epochs):\n",
    "        for sample in data:\n",
    "            i = step % batch_size\n",
    "            X[i] = sample[:-1]\n",
    "            Y[i] = sample[-1:]\n",
    "            step += 1\n",
    "            if not step % batch_size:\n",
    "                yield X, Y, e, step\n",
    "    pass\n",
    "\n",
    "nn = NeuralNetwork(\n",
    "    gen_data(data, 10, 1),\n",
    "    gen_data(data, 2, 1),\n",
    "    SOS,\n",
    "    SOS\n",
    ")\n",
    "\n",
    "#fix the random seed for the reproducibility.\n",
    "#(another hyper-param)\n",
    "np.random.seed(1)   \n",
    "\n",
    "Fc1 = FcLayer(np.random.rand(2,4), #weights\n",
    "              np.random.rand(4), #bias\n",
    "              ReLU, #act func\n",
    "              nn.gen_input(),\n",
    "              None\n",
    "             )\n",
    "\n",
    "Fc2 = FcLayer(np.random.rand(4,2),\n",
    "              np.random.rand(2),\n",
    "              ReLU,\n",
    "              Fc1.poll_forward(),\n",
    "              Fc1.push_backward\n",
    "             )\n",
    "\n",
    "Out = FcLayer(np.random.rand(2,1),\n",
    "              np.random.rand(1),\n",
    "              ReLU,\n",
    "              Fc2.poll_forward(),\n",
    "              Fc2.push_backward\n",
    "             )\n",
    "\n",
    "for Z in nn.train(Out, 0.1, 1e-5):\n",
    "    print(Out.y, nn.Y, Z)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,1,2,3]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
