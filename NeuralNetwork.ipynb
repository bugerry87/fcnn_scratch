{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning HW01\n",
    "Gerald Baulig 0780827 2019/11/03\n",
    "\n",
    "In this assignment we are asked to implement a neural network from scratch,\n",
    "including Backpropagation and Storastic Gradient Decent algorithms.\n",
    "The assigment includes two tasks:\n",
    "\n",
    "1. Implement a regression network, and\n",
    "2. implement a classification network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a Regression Network\n",
    "\n",
    "Implement a regression network for the engery efficiency dataset.\n",
    "I guess this dataset descripes the termal exchange of a building to its environment.\n",
    "The dataset has 2 Values (t):\n",
    "\n",
    "- Heating load, and\n",
    "- Cooling load\n",
    "\n",
    "And 8 features:\n",
    "\n",
    "- Relative compactness,\n",
    "- Surface area,\n",
    "- Wall area,\n",
    "- Roof area,\n",
    "- Overall hight,\n",
    "- Orientation,\n",
    "- Glazing area, and\n",
    "- Glazing area distribution.\n",
    "\n",
    "We are required to define a feature-vector out of these features and predict the heating load of the buildings, by minimizing the \"sum-of-squares\" error function,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E(w) = \\sum_{n=1}^{N}{(t_n - y(X_n;w))^2}\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "...while the evaluation should be processed by the \"root-mean-square\" error (basically an Euclidean distance :-),\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "E_{RMS}(w) = \\frac{\\sqrt{\\sum_{n=1}^{N}{(t_n - y(x_n;w))^2}}}{\\sqrt{N}}\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement a Classifier\n",
    "\n",
    "Implement a classification network for the Ionosphere dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Fully-Connected Neural Network from Scratch\n",
    "\n",
    "First, let's define what a Neural Network is.\n",
    "A Neural Network is a class that can train and validate the weight of a stack of layers, w.r.t several hyper-parameters.\n",
    "However, all what the Neural Network needs to know about his own network is the Input-Layer. Furthermore, the hyper-parameters are only required in the training process, but only few of them in the validation process,\n",
    "such that the class defination could look like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_layer):\n",
    "        self.input_layer = input_layer\n",
    "        pass\n",
    "    \n",
    "def train(self, min_batch=1, epochs=1, lr=1):\n",
    "    print(\"train\")\n",
    "    pass\n",
    "\n",
    "NeuralNetwork.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "class FcLayer:\n",
    "    def __init__(self, weights, biases, act_func):\n",
    "        self.w = weights\n",
    "        self.b = biased\n",
    "        self.af = act_func\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 5. 0. 0.]\n",
      "[1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def ReLU():\n",
    "    ReLU.f = lambda x: np.maximum(x,0).astype(float)\n",
    "    ReLU.d = lambda x: (np.array(x) > 0).astype(float)\n",
    "    pass\n",
    "ReLU() #init\n",
    "\n",
    "#test\n",
    "print(ReLU.f([1,-1,5,-5,0]))\n",
    "print(ReLU.d([1,-1,5,-5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73105858 0.26894142 0.99330715 0.00669285 0.5       ]\n",
      "[0.19661193 0.19661193 0.00664806 0.00664806 0.25      ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Sigmoid():\n",
    "    f = lambda x: 1 / (1 + np.exp(-np.array(x)))\n",
    "    def d(x):\n",
    "        S = Sigmoid.f(x)\n",
    "        return S * (1 - S)\n",
    "    pass\n",
    "Sigmoid() #init\n",
    "\n",
    "#test\n",
    "print(Sigmoid.f([1,-1,5,-5,0]))\n",
    "print(Sigmoid.d([1,-1,5,-5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
